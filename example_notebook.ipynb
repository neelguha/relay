{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relay Example Notebook\n",
    "\n",
    "This notebook demonstrates how to use Relay to:\n",
    "1. Submit batch jobs\n",
    "2. Track job progress\n",
    "3. Retrieve results from old jobs\n",
    "\n",
    "The key feature of Relay is that all jobs and results are stored in a workspace directory, so you can access them across sessions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and set up the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from relay import RelayClient, BatchRequest\n",
    "\n",
    "# Check if API key is set\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    print(\"⚠️  Warning: OPENAI_API_KEY not set. Set it with:\")\n",
    "    print(\"   export OPENAI_API_KEY='your-api-key'\")\n",
    "else:\n",
    "    print(\"✓ OPENAI_API_KEY is set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Submitting Jobs\n",
    "\n",
    "Create a workspace and submit some batch jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a workspace - all jobs will be stored here\n",
    "workspace_dir = \"example_workspace\"\n",
    "relay = RelayClient(directory=workspace_dir)\n",
    "\n",
    "print(f\"✓ Created workspace: {workspace_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some batch requests\n",
    "requests = [\n",
    "    BatchRequest(\n",
    "        id=\"req-1\",\n",
    "        model=\"gpt-4o-mini\",\n",
    "        system_prompt=\"You are a helpful assistant.\",\n",
    "        prompt=\"What is 2+2?\",\n",
    "        provider_args={}\n",
    "    ),\n",
    "    BatchRequest(\n",
    "        id=\"req-2\",\n",
    "        model=\"gpt-4o-mini\",\n",
    "        system_prompt=\"You are a helpful assistant.\",\n",
    "        prompt=\"What is the capital of France?\",\n",
    "        provider_args={}\n",
    "    ),\n",
    "    BatchRequest(\n",
    "        id=\"req-3\",\n",
    "        model=\"gpt-4o-mini\",\n",
    "        system_prompt=\"You are a helpful assistant.\",\n",
    "        prompt=\"Explain quantum computing in one sentence.\",\n",
    "        provider_args={}\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"Created {len(requests)} requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit the batch job with a unique ID\n",
    "job_id = \"notebook-demo-001\"\n",
    "\n",
    "try:\n",
    "    job = relay.submit_batch(\n",
    "        requests=requests,\n",
    "        job_id=job_id,\n",
    "        provider=\"openai\",\n",
    "        description=\"Notebook demonstration batch job\"\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Job submitted successfully!\")\n",
    "    print(f\"  Job ID: {job.job_id}\")\n",
    "    print(f\"  Submitted at: {job.submitted_at}\")\n",
    "    print(f\"  Status: {job.status}\")\n",
    "    print(f\"  Number of requests: {job.n_requests}\")\n",
    "    \n",
    "except ValueError as e:\n",
    "    print(f\"✗ Error: {e}\")\n",
    "    print(\"This might mean the job already exists. Try a different job_id.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Tracking Jobs\n",
    "\n",
    "List all jobs in the workspace and monitor their progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all jobs in the workspace\n",
    "all_jobs = relay.list_jobs()\n",
    "print(f\"Found {len(all_jobs)} job(s) in workspace:\")\n",
    "for jid in all_jobs:\n",
    "    print(f\"  - {jid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get detailed information about a specific job\n",
    "job_info = relay.get_job(job_id)\n",
    "if job_info:\n",
    "    print(f\"Job: {job_info['job_id']}\")\n",
    "    print(f\"  Description: {job_info['description']}\")\n",
    "    print(f\"  Provider: {job_info['provider']}\")\n",
    "    print(f\"  Status: {job_info['status']}\")\n",
    "    print(f\"  Submitted: {job_info['submitted_at']}\")\n",
    "    print(f\"  Requests: {job_info['n_requests']}\")\n",
    "    print(f\"  Completed: {job_info.get('completed_requests', 0)}\")\n",
    "    print(f\"  Failed: {job_info.get('failed_requests', 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor job progress\n",
    "print(f\"Monitoring job: {job_id}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "max_checks = 30  # Maximum number of status checks\n",
    "check_interval = 5  # Check every 5 seconds\n",
    "\n",
    "for i in range(max_checks):\n",
    "    job_status = relay.monitor_batch(job_id)\n",
    "    \n",
    "    print(f\"\\n[{i * check_interval}s] Status: {job_status.status}\")\n",
    "    if hasattr(job_status, 'completed_requests'):\n",
    "        print(f\"  Progress: {job_status.completed_requests}/{job_status.n_requests} completed\")\n",
    "    \n",
    "    if job_status.status == \"completed\":\n",
    "        print(\"\\n✓ Batch job completed!\")\n",
    "        break\n",
    "    elif job_status.status == \"failed\":\n",
    "        print(\"\\n✗ Batch job failed!\")\n",
    "        break\n",
    "    elif job_status.status in [\"validating\", \"in_progress\", \"finalizing\"]:\n",
    "        print(f\"  Waiting... (checking again in {check_interval}s)\")\n",
    "        time.sleep(check_interval)\n",
    "    else:\n",
    "        print(f\"  Unknown status, waiting...\")\n",
    "        time.sleep(check_interval)\n",
    "else:\n",
    "    print(f\"\\n⚠ Maximum checks ({max_checks}) reached. Job may still be processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Getting Results from Old Jobs\n",
    "\n",
    "This is the key feature - you can create a new RelayClient instance with the same workspace directory and access all previous jobs and their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate starting a new session - create a new RelayClient with the same workspace\n",
    "print(\"Simulating a new session...\")\n",
    "print(f\"Creating new RelayClient with workspace: {workspace_dir}\")\n",
    "\n",
    "new_relay = RelayClient(directory=workspace_dir)\n",
    "print(\"✓ New RelayClient created\")\n",
    "\n",
    "# All jobs are still accessible!\n",
    "existing_jobs = new_relay.list_jobs()\n",
    "print(f\"\\nFound {len(existing_jobs)} existing job(s):\")\n",
    "for jid in existing_jobs:\n",
    "    print(f\"  - {jid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if results exist for a job\n",
    "if new_relay.has_results(job_id):\n",
    "    print(f\"✓ Results exist for {job_id}\")\n",
    "else:\n",
    "    print(f\"✗ No results found for {job_id}\")\n",
    "    print(\"  (Results are saved when you call retrieve_batch_results)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve results - this will fetch from API if not cached, or use cache if available\n",
    "print(f\"Retrieving results for {job_id}...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    results = new_relay.retrieve_batch_results(job_id)\n",
    "    \n",
    "    print(f\"\\n✓ Retrieved {len(results)} results\")\n",
    "    print(f\"\\nResults are automatically saved to: {workspace_dir}/{job_id}_results.json\")\n",
    "    \n",
    "    # Display sample results\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Sample Results:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, result in enumerate(results[:3], 1):  # Show first 3\n",
    "        print(f\"\\nResult {i}:\")\n",
    "        custom_id = result.get('custom_id', 'N/A')\n",
    "        print(f\"  Request ID: {custom_id}\")\n",
    "        \n",
    "        # Extract response based on OpenAI format\n",
    "        if 'response' in result:\n",
    "            response = result['response']\n",
    "            if 'body' in response:\n",
    "                body = response['body']\n",
    "                if 'output' in body:\n",
    "                    output = body['output']\n",
    "                    # Truncate long outputs\n",
    "                    output_str = str(output)\n",
    "                    if len(output_str) > 200:\n",
    "                        output_str = output_str[:200] + \"...\"\n",
    "                    print(f\"  Output: {output_str}\")\n",
    "        \n",
    "        if 'error' in result:\n",
    "            print(f\"  Error: {result['error']}\")\n",
    "    \n",
    "    if len(results) > 3:\n",
    "        print(f\"\\n  ... and {len(results) - 3} more results\")\n",
    "        \n",
    "except ValueError as e:\n",
    "    print(f\"✗ Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results from cache (doesn't fetch from API)\n",
    "print(\"Getting results from cache (no API call)...\")\n",
    "cached_results = new_relay.get_results(job_id)\n",
    "\n",
    "if cached_results:\n",
    "    print(f\"✓ Found {len(cached_results)} cached results\")\n",
    "    print(\"  (These were loaded from disk, no API call was made)\")\n",
    "else:\n",
    "    print(\"✗ No cached results found\")\n",
    "    print(\"  (Call retrieve_batch_results first to fetch and cache results)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force refresh results (bypass cache)\n",
    "print(\"Force refreshing results (bypassing cache)...\")\n",
    "try:\n",
    "    fresh_results = new_relay.retrieve_batch_results(job_id, force_refresh=True)\n",
    "    print(f\"✓ Retrieved {len(fresh_results)} fresh results from API\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Submitting Jobs**: Create a workspace and submit batch jobs with unique IDs\n",
    "2. **Tracking Jobs**: List jobs, get job info, and monitor progress\n",
    "3. **Getting Results from Old Jobs**: Create a new RelayClient with the same workspace to access all previous jobs and results\n",
    "\n",
    "### Key Benefits:\n",
    "\n",
    "- **Persistent Storage**: All jobs and results are saved to the workspace directory\n",
    "- **Session Independence**: You can close and reopen notebooks - all jobs are still accessible\n",
    "- **Result Caching**: Results are cached on disk, so you don't need to re-fetch from the API\n",
    "- **Easy Sharing**: Share the workspace directory to share all jobs and results\n",
    "\n",
    "### Workspace Structure:\n",
    "\n",
    "```\n",
    "example_workspace/\n",
    "  notebook-demo-001.json              # Job metadata\n",
    "  notebook-demo-001_results.json       # Results (when retrieved)\n",
    "  ...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
